[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About me",
    "section": "",
    "text": "My current objectives are to start a family, expand my volunteering in my community, and to get accepted into a Statistics PhD program! I love to learn about anything statistics related, but in particular I enjoy financial related data. Housing prices, stock predictions, GDP forecasting, and risk assessments all come to mind. I am excited to not only learn about new models and methods to make predicitions, someday I hope to be able to make my own prediction models that are used in industry."
  },
  {
    "objectID": "classes.html",
    "href": "classes.html",
    "title": "Classes",
    "section": "",
    "text": "A list of classes I feel were particularly interesting!"
  },
  {
    "objectID": "classes.html#certifications",
    "href": "classes.html#certifications",
    "title": "Classes",
    "section": "Certifications",
    "text": "Certifications\n AWS Cloud Practitioner"
  },
  {
    "objectID": "classes.html#data-science",
    "href": "classes.html#data-science",
    "title": "Classes",
    "section": "Data Science",
    "text": "Data Science\n\nData Science 201: Introduction to Data Science\nBasics and introduction to a variety of methods of modeling in Python. Included linear and multi-linear regressions, logistic regression, basic supervised learning with random forests and decision trees, as well as k-means clustering and a brief introduction into unsupervised learning. Model metrics and comparisons, as well as basic statistical concepts were taught."
  },
  {
    "objectID": "classes.html#computer-science",
    "href": "classes.html#computer-science",
    "title": "Classes",
    "section": "Computer Science",
    "text": "Computer Science\n\nComputer Science 227: Introduction to Object Oriented Programming\nIntroduction to the basics of both Java and Object Oriented Programming as a whole. Focus on abstraction, encapsulation, and an early introduction to commonly used algorithms.\n\n\nComputer Science 228: Introduction to Data Structures\nCovers all of the usual data structures in programming, lists, arrayLists, doubly linked lists, trees, binary trees, hashmaps, stacks, queues, and many more! Class taught in Java.\n\n\nComputer Science 311: Introduction to Design and Analysis of Algorithms\nIntroduction to graph algorithms, dyanmic programming, runtime analysis, and proof of correctness for written algorithms. Basic introduction to the concept of P and NP problems. Emphasis on divide and conquer, recursive, and memoization.\n\n\nComputer Science 363: Introduction to Database Management Systems\nIntroduction to SQL style database management, primarily using MySQL. Querying using SQL, and query optimization using different joins. Two phase locking, relational algebra, and other database concepts discussed. Brief introduction to graph databases such as Neo4j.\n\n\nComputer Engineering 419: Software Tools for Large Scale Data Analysis\nIntroduction to Hadoop, distributed databases, and Apache Spark. Looking at issues regarding data durability, and consistency, issues in unstructured and bulk data. Variety of languages and programming abilities used including Pig, Java, Linux systems, and writing parralel code to be run on a cluster.\n\n\nComputer Science 511: Design and Analysis of Algorithms\nGraduate level class that looks at advanced algorithms and handling of P and NP problems. A focus on the Bellman-Ford Method of handling flow networks, conversion between NP Problems and proofs concerning NP completeness, and estimation and heuristic approximations to NP problems."
  },
  {
    "objectID": "classes.html#statistics",
    "href": "classes.html#statistics",
    "title": "Classes",
    "section": "Statistics",
    "text": "Statistics\n\nStatistics 347: Probability and Theory for Data Science\nTheoretical statistics, introduction to a variety of distributions such as binomial, geometric, poisson, normal, gamma, and beta. A variety proofs concerning those distributions in their moment generating functions, expected values and more. Also featured an introduction to point estimators, confidence intervals, and hypothesis testing. Heavy focus on use of R and statistical simulation.\n\n\nStatistics 477: Introduction to categorical variables\nIntroduction to the handling of categorical variables including hypothesis testing, confidence intervals, sampling sizes, tests of independence. Emphasis on visualization as well as numerical summaries. Heavy focus on use of R and statistical simulation.\n\n\nStatistics 588: Statistical Theory for Research Workers\nGraduate level class that gives a more advanced and applied look at distributions with a heavier focus on their applications in research. A variety of new distributions were taught, and an emphasis on learning when and how to model real world data using the distributions in class. R was used for simulations"
  },
  {
    "objectID": "experience.html",
    "href": "experience.html",
    "title": "Experience",
    "section": "",
    "text": "Undergraduate Research Assistant\nAugust 2022 - Present, Center for Statistical and Forensic Evidence, Ames, IA\n\nRefined previous machine learning models to improve metrics and consistency\nReviewed operating policies to ensure statistics included were rigorous and accurate\nCreated dashboards and web apps to make machine learning more accessible\n\n\n\n Machine Learning Engineering Intern\nMay 2022 - August 2022, Principal Financial Group, Des Moines, IA\n\nDeveloped extensively with AWS Sagemaker, S3, native Sagemaker models, and SKLearn models to train, tune, and test a variety of binary classification models\nPresented and endorsed XGBoost model to business partners throughout the enterprise\nResearched and developed autonomous ML pipelines to ensure that batch predictions were delivered securely and efficiently on a routine basis\n\n\n\n Software Engineering Intern\nMay 2021 - August 2021, Principal Financial Group, Des Moines, IA\n\nDeployed applications and set up automated jobs using Jenkins\nDeveloped a data pipeline on AWS from web apps using Kinesis and Elastic Server\nLed a team to create a Django website for recruiting employees in a 40-hour hackathon\n\n\n\nWeb Developer Intern\nJanuary 2021 - May 2021, eFuneral Solutions, Ames, IA\n\nCreated automated email systems with Elastic Email services in C#\nResolved Jira tickets concerning Stripe, SalesForce, and AWS logging issues\n\n\n\n Security Officer\nJune 2020 - Present, Defense Contracting Activities, Ames IA\n\nSecured a USDA facility ensuring all personnel who entered had proper authorization\nMedical training, CPR and Stop the Bleed certified\n\n\n\n Section Supervisor\nAugust 2019 - May 2020, US Marine Corps, Jacksonville, NC\n\nSupervised, trained, and mentored 14 employees, coordinating different sections and acting as a subject matter expert to higher staff and managers\nSelf-taught online Oracle Applications supply system, ordering over $10,000 worth of parts and handling all modifications and upgrades needed for systems\n\n\n\n Team Leader\nMarch 2017 - August 2019, US Marine Corps, Jacksonville, NC\n\nLed a team of nine employees to complete a variety of objectives in two countries\nLed experimental operations to develop policies and SOP’s for newly introduced technologies\n\n\n\n Radio Operator\nJune 2015 - March 2017, US Marine Corps, Jacksonville, NC\n\nMaintained over 200 secure radio keys and $400,000 worth of classified equipment with 100% accountability.\nHad to develop creative new antennas to overcome rapidly changing terrain conditions."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Recent Activities\n\n\nResearch\nWith the aid of Dr. Hofmann and Naga Vempati, I am working to develop an RShiny application that uses machine learning to determine if microscopy scans on bullets are of high quality, and can be processed, or if they need to be re-done by the individual doing the scans.\n\n\n\nUpcoming Internship\nSummer 2023 I will be working as a Data Analyst for Betchtel Plant Machinery inc., stay tuned for more information!\n\n\nClasses\nThis semester I am taking statistic classes that focus on theoretical distributions, and categorical variable analysis. As well as a programming course that focuss on large NoSQL databases such as Hadoop and Apache Spark"
  },
  {
    "objectID": "myProjects/401k-rollover.html",
    "href": "myProjects/401k-rollover.html",
    "title": "PFG 401k Rollover Project",
    "section": "",
    "text": "All data and products were stored on the Principal servers, so unfortunately I can’t share too much about it. The project involved a variety of factors including numerical and categorical. Extensive data cleaning was required, much of it involved contacting other parties and verifying what was a reasonable boundary for a particular feature, and then excluding any rows in the data that were outside of the boundaries.\nWe fit approximate ten different models and compared them all to see which gave us the best AUC and F1score. The model was a prototype, so more specific hyper parameter tuning was left to be decided by the particular client it went to. If the mass-email team got a version, they would want higher recall, or in other words, its better to send more emails and bother people than it is to send less emails and miss potential customers. However if the model was given to the call center, the opposite would be true, you would tune for percision, or in other words its better to miss out on potential clients, as long as the ones we are calling are sure bets. Our base model attempted to find the happy medium using the F1score.\nThe model used several hundred thousand rows of data and about 80 columns worth features. We used an XGBoost model on AWS Sagemaker."
  },
  {
    "objectID": "myProjects/nat-gas.html",
    "href": "myProjects/nat-gas.html",
    "title": "Natural Gas Price Predicition",
    "section": "",
    "text": "The price of Natural Gas is highly seasonal, and is very dependent on political and environmental effects.There is significant variability even over the course of a year, and between 2000 and 2010, there was a significant change in the baseline price. In about 2008 there was a significant outlier in the price of natural gas. Since 2008, the variability of the price of natural gas has increased, but the mean price from an initial guess is fairly constant. Below is a time chart of the price of natural gas, data points were monthly.\n\n\n\nNatural Gas Prices\n\n\nThe first and most obvious idea I had to try and capture seasonality was to track monthly change in price. The price of natural gas goes up, and is more volatile in the summer months.\n\n\n\nNatural Gas Monthly Variability\n\n\nNow to try a new modelling method I had never attempted before, I tried to fit an ANOVA model, this required me to check if the data was stationary, and if it had significant correlation. In the chart below, if the lines go outside the blue shaded zone, it fails the correlation test. You can see that in this data, the data didn’t pass very comfortably, which means I would need to do some transformations of the data to ensure the ANOVA fit goes correctly. For the purposes of the class, I decided to press anyways. In the future, significant data manipulation would be required.\n\n\n\nNatural Gas Monthly Variability\n\n\nTo fit the model, I used all the data up until 2021-02 for training, and all the other data as test data. I used the statsmodels.tsa.holtwinters package to fit the ANOVA model, and it produced the following chart that shows the breakdown of our data. The ANOVA equation is simply put (Price = Trend + Seasonal + Residual).\n\n\n\nNatural Gas Monthly Variability\n\n\nI compared the modeling predictions against the test data, and we can see that the residual model is quite close to the actual price. The \\(R^2\\) value is 0.925. So our model did surprisingly well considering we only used time data to predict it! There are many variables related to the price, and we didn’t consider most of them.\n\n\n\nNatural Gas Test Predictions\n\n\nFinally, we make a prediction of the (at the time) future!\n\n\n\nNatural Gas Future Predictions"
  },
  {
    "objectID": "my_projects.html",
    "href": "my_projects.html",
    "title": "Projects",
    "section": "",
    "text": "Natural Gas Price Predicition\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n\n\n\n\n\n\n\n\nPFG 401k Rollover Project\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\nNo matching items"
  },
  {
    "objectID": "publications.html",
    "href": "publications.html",
    "title": "Publications",
    "section": "",
    "text": "While an Undergraduate Research Assistant at the Center for Statistical Analysis of Forensic Evidence, I worked for Dr. Heike Hofmann with my teammate Naga Vempati to make an application in R that evaluates the quality of a given bullet scan to see if it will be adequate for striation comparison to another bullet. The intention of said comparison is to see if the bullets can reasonably be determined to have been fired from the same barrel.\nMany of the images such as the one below suffer from a variety of problems, namely holes and feathering. The app is a random forest model that uses seven features to predict the quality of the a scan. The particular problem of the image is also assesed. Five random forests, one for each tracked kind of problem, and lack thereof, each doing a binary comparison to detect if its particular problem is present. The max problem score is selected as the particular problem.\n\n\n\nBullet Striation with Missing Sections"
  }
]